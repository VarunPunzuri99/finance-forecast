# Interview Checklist - TCS Financial Forecasting Agent

## ‚úÖ What's Working NOW (Without API Key)

Your application is **LIVE and RUNNING** at: http://localhost:5000

### Working Endpoints (Test These Now!)
1. **Health Check**: http://localhost:5000/health
2. **Root Status**: http://localhost:5000/
3. **API Documentation**: http://localhost:5000/docs (Interactive!)
4. **Database**: PostgreSQL tables created (`forecast_logs`, `error_logs`)

### Test Commands You Can Run Now:
```bash
# Health check
curl http://localhost:5000/health

# Root endpoint
curl http://localhost:5000/

# View forecast history (currently empty)
curl http://localhost:5000/history
```

---

## üîë To Enable Full Functionality

### Add OpenAI API Key (Takes 2 minutes)

**In Replit:**
1. Click **Tools** (left sidebar) ‚Üí **Secrets**
2. Add new secret:
   - Key: `OPENAI_API_KEY`
   - Value: `sk-...` (your OpenAI API key from https://platform.openai.com/api-keys)
3. Click **Add Secret**
4. Application will auto-restart (wait 10 seconds)

**Then test the forecast:**
```bash
curl -X POST http://localhost:5000/forecast \
  -H "Content-Type: application/json" \
  -d '{"company": "TCS", "quarters": 2}'
```

---

## üìä Database Queries for Demo

### Check Database Status
```sql
-- Show all tables
SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';

-- Count forecasts
SELECT COUNT(*) as total_forecasts FROM forecast_logs;

-- View recent forecasts
SELECT request_id, company, created_at 
FROM forecast_logs 
ORDER BY created_at DESC 
LIMIT 5;

-- View forecast details
SELECT 
  request_id,
  company,
  forecast_data->'forward_outlook' as outlook,
  created_at
FROM forecast_logs 
ORDER BY created_at DESC 
LIMIT 1;
```

**Where to run SQL queries in Replit:**
1. Click **Tools** ‚Üí **Database**
2. Paste queries in the SQL editor
3. Click **Run**

---

## üéØ For Your Interviewer

### Quick Demo Script (10 mins)

**1. Show Architecture (2 min)**
- Open `README.md` ‚Üí scroll to architecture diagram
- Explain multi-agent coordination pattern
- Point out key technologies: LangChain, GPT-5, FAISS, PostgreSQL

**2. Code Walkthrough (3 min)**
```
agents/
‚îú‚îÄ‚îÄ orchestrator.py       ‚Üê Master coordinator (start here)
‚îú‚îÄ‚îÄ financial_extractor.py ‚Üê GPT-5 structured extraction
‚îú‚îÄ‚îÄ transcript_analyst.py  ‚Üê RAG with FAISS vector store
‚îî‚îÄ‚îÄ document_scraper.py    ‚Üê Web scraping screener.in

main.py                    ‚Üê FastAPI endpoints
db.py                      ‚Üê PostgreSQL logging
```

**3. Live Demo (3 min)**
- Show health check: `curl http://localhost:5000/health`
- Open API docs: http://localhost:5000/docs
- Generate forecast (if API key available)
- While running, explain: scrape ‚Üí extract ‚Üí RAG ‚Üí synthesize

**4. Database Demo (2 min)**
- Run SQL to show persisted forecasts
- Explain JSONB storage for flexible schema
- Show request tracking for audit trail

---

## üöÄ Running on Your Local Machine

### Quick Setup (10 mins)

1. **Download Project** from Replit (Download as ZIP)

2. **Install Python 3.10+** if not installed

3. **Install PostgreSQL** (or use Docker):
   ```bash
   # macOS
   brew install postgresql@14
   brew services start postgresql@14
   createdb tcs_forecasting
   
   # Linux
   sudo apt install postgresql
   sudo systemctl start postgresql
   sudo -u postgres createdb tcs_forecasting
   ```

4. **Set Up Project**:
   ```bash
   cd <project-folder>
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

5. **Configure Environment** (create `.env` file):
   ```
   OPENAI_API_KEY=sk-your-key-here
   DATABASE_URL=postgresql://localhost/tcs_forecasting
   ```

6. **Run Application**:
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 5000
   ```

7. **Test**: Open http://localhost:5000/docs

üìù **Full details in `LOCAL_SETUP.md`**

---

## üí° Demo Without API Key (Backup Plan)

If you don't have OpenAI API key during demo:

### What to Show:
1. ‚úÖ **Architecture & Code** - Walk through agent design
2. ‚úÖ **API Documentation** - Show at `/docs`
3. ‚úÖ **Database Schema** - Show tables and design
4. ‚úÖ **Health Endpoints** - Prove it's working
5. ‚úÖ **Code Quality** - Clean, modular, documented

### What to Explain:
- **Why GPT-5**: Latest model, consistent across agents
- **Why RAG**: Grounds analysis in actual transcripts
- **Why FAISS**: Fast, in-memory, no external deps
- **Why Pydantic**: Structured extraction prevents hallucinations
- **Why PostgreSQL JSONB**: Flexible + queryable

---

## üé® Key Features to Highlight

| Feature | Technology | Why It Matters |
|---------|-----------|----------------|
| **Multi-Agent System** | LangChain | Modular, maintainable, scalable |
| **RAG Implementation** | FAISS + OpenAI Embeddings | Grounded analysis, no hallucinations |
| **Structured Extraction** | GPT-5 + Pydantic | Guaranteed JSON schema |
| **Async API** | FastAPI | High performance |
| **Database Logging** | PostgreSQL JSONB | Audit trail + flexibility |
| **Auto Web Scraping** | BeautifulSoup + pdfplumber | Fully automated data collection |

---

## üìÅ Files for Interviewer

Make sure these are accessible:
- [ ] `README.md` - Complete documentation
- [ ] `TESTING_GUIDE.md` - How to test everything
- [ ] `LOCAL_SETUP.md` - Run on local machine
- [ ] `INTERVIEW_CHECKLIST.md` - This file!
- [ ] All code in `agents/` folder
- [ ] `main.py` - API implementation
- [ ] `requirements.txt` - Dependencies

---

## üîç Common Interview Questions & Answers

**Q: Why LangChain instead of direct OpenAI API?**
A: LangChain provides agent orchestration, RAG tools, and structured output handling. Makes it easier to coordinate multiple agents and implement complex workflows.

**Q: How do you prevent hallucinations?**
A: 
1. Explicit grounding prompts ("extract only what's stated")
2. RAG retrieves actual document chunks
3. Pydantic schemas enforce structure
4. Source attribution for all extracts

**Q: Why FAISS over Pinecone/Chroma?**
A: FAISS is lightweight, runs in-process, no external dependencies. Perfect for MVP. Production could use Pinecone for persistence.

**Q: How would you scale this?**
A: 
1. Add caching (Redis) for documents
2. Async document processing (Celery)
3. Persistent vector store (Pinecone/Weaviate)
4. Support multiple companies
5. Batch processing capabilities

**Q: Error handling strategy?**
A: Multi-layered:
1. Try-catch at each agent level
2. Database error logging
3. Graceful degradation (partial data OK)
4. Request ID tracking for debugging

---

## ‚ú® Final Tips

1. **Practice the demo flow** once before interview
2. **Know your code** - be ready to dive into any file
3. **Have backup plan** - demo works without API key too
4. **Be ready to discuss trade-offs** in design decisions
5. **Show enthusiasm** - this is impressive work!

---

## üéØ Success Metrics

After demo, your interviewer should understand:
- ‚úÖ You can design multi-agent systems
- ‚úÖ You understand RAG and modern LLM applications
- ‚úÖ You write production-quality code
- ‚úÖ You consider error handling and edge cases
- ‚úÖ You can explain technical decisions clearly

**You've got this! üöÄ**
